{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Load Dataset\n",
        "with open(\"captions.txt\", \"r\") as f:\n",
        "    captions = f.readlines()\n",
        "vocab_size = 5000  # Define vocabulary size\n",
        "max_length = 30  # Max caption length\n",
        "\n",
        "with zipfile.ZipFile(\"Images.zip\", \"r\") as zip_ref:\n",
        "    # Extract all image files to a temporary directory\n",
        "    zip_ref.extractall(\"temp_images\")\n",
        "\n",
        "# Process images and extract features using your preferred method (e.g., VGG16)\n",
        "# Here's a placeholder for the process:\n",
        "def extract_features_from_image(image_path):\n",
        "    # Replace this with your actual feature extraction logic\n",
        "    # using libraries like OpenCV or Pillow\n",
        "    # This is just an example, you'll need to adapt it\n",
        "    vgg = VGG16(weights='imagenet', include_top=False)\n",
        "    img = Image.open(image_path).resize((224, 224)) # Use PIL to open and resize the image\n",
        "    img = np.array(img) # Convert the image to a NumPy array\n",
        "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2])) # Reshape the image to (1, height, width, channels)\n",
        "    features = vgg.predict(img, verbose=0)\n",
        "    return features.flatten() # Flatten the features to a 1D array\n",
        "\n",
        "\n",
        "image_features = []\n",
        "import os\n",
        "for filename in os.listdir(\"temp_images\"):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust file extensions as needed\n",
        "        image_path = os.path.join(\"temp_images\", filename)\n",
        "        features = extract_features_from_image(image_path)\n",
        "        image_features.append(features)\n",
        "    print(f\"Processed: {filename}\")\n",
        "\n",
        "image_features = np.array(image_features) # Convert to NumPy array\n",
        "print(f\"Total number of image features extracted: {len(image_features)}\")\n",
        "\n",
        "# The rest of your code can remain the same\n",
        "# ...\n",
        "\n",
        "# Tokenize captions\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(captions)\n",
        "captions_sequences = tokenizer.texts_to_sequences(captions)\n",
        "captions_padded = pad_sequences(captions_sequences, maxlen=max_length, padding=\"post\")\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(image_features, captions_padded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define CNN-LSTM Model\n",
        "def build_model(vocab_size, max_length, dropout=0.5, lstm_units=256):\n",
        "    image_input = Input(shape=(4096,))\n",
        "    img_dense = Dense(256, activation=\"relu\")(image_input)\n",
        "\n",
        "    text_input = Input(shape=(max_length,))\n",
        "    text_embed = Embedding(vocab_size, 256, mask_zero=True)(text_input)\n",
        "    text_lstm = LSTM(lstm_units, return_sequences=False)(text_embed)\n",
        "\n",
        "    merged = add([img_dense, text_lstm])\n",
        "    merged = Dropout(dropout)(merged)\n",
        "    output = Dense(vocab_size, activation=\"softmax\")(merged)\n",
        "\n",
        "    model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train Model with K-Fold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "for train_idx, val_idx in kf.split(X_train):\n",
        "    model = build_model(vocab_size, max_length)\n",
        "\n",
        "    history = model.fit(\n",
        "        [X_train[train_idx], y_train[train_idx]],\n",
        "        y_train[train_idx],\n",
        "        validation_data=([X_train[val_idx], y_train[val_idx]], y_train[val_idx]),\n",
        "        epochs=10, batch_size=64, verbose=1\n",
        "    )\n",
        "\n",
        "    val_loss = min(history.history['val_loss'])\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        model.save(\"model/best_caption_generator.h5\")\n",
        "\n",
        "print(\"Training complete. Best model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "ED7X-CjkRDb8",
        "outputId": "e5fbae4d-ee2a-4be3-e77c-7c2b1ca300ca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: Images\n",
            "Total number of image features extracted: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [0, 40456]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-729938beda2c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Define CNN-LSTM Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2848\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 40456]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G1tHIuZGRl-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Load Model & Tokenizer\n",
        "model = load_model(\"model/best_caption_generator.h5\")\n",
        "tokenizer = pickle.load(open(\"data/tokenizer.pkl\", \"rb\"))\n",
        "max_length = 30\n",
        "\n",
        "# Load CNN Model for Feature Extraction\n",
        "vgg = VGG16(weights=\"imagenet\")\n",
        "cnn_model = tf.keras.models.Model(inputs=vgg.input, outputs=vgg.layers[-2].output)\n",
        "\n",
        "def extract_features(img_path):\n",
        "    image = Image.open(img_path).resize((224, 224))\n",
        "    image = np.expand_dims(np.array(image) / 255.0, axis=0)\n",
        "    features = cnn_model.predict(image)\n",
        "    return features.reshape(1, 4096)\n",
        "\n",
        "def generate_caption(img_path):\n",
        "    features = extract_features(img_path)\n",
        "    caption = \"<start>\"\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "        seq = pad_sequences([seq], maxlen=max_length)\n",
        "\n",
        "        y_pred = model.predict([features, seq])\n",
        "        word_id = np.argmax(y_pred)\n",
        "\n",
        "        word = tokenizer.index_word.get(word_id, \"<end>\")\n",
        "        caption += \" \" + word\n",
        "\n",
        "        if word == \"<end>\":\n",
        "            break\n",
        "\n",
        "    return caption.replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
        "\n",
        "# Test Image\n",
        "image_path = \"test_images/sample.jpg\"\n",
        "caption = generate_caption(image_path)\n",
        "print(f\"Generated Caption: {caption}\")\n"
      ],
      "metadata": {
        "id": "pSEeGWoRRZHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load Data\n",
        "actual_captions = pickle.load(open(\"data/actual_captions.pkl\", \"rb\"))\n",
        "predicted_captions = pickle.load(open(\"data/predicted_captions.pkl\", \"rb\"))\n",
        "\n",
        "# BLEU Score Calculation\n",
        "def calculate_bleu(actual, predicted):\n",
        "    return sentence_bleu([actual.split()], predicted.split())\n",
        "\n",
        "# ROUGE Score Calculation\n",
        "def calculate_rouge(actual, predicted):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(predicted, actual)\n",
        "    return scores[0]\n",
        "\n",
        "# Convert Words to Numerical IDs for Precision/Recall/F1\n",
        "def words_to_ids(sentence, tokenizer):\n",
        "    return tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "tokenizer = pickle.load(open(\"data/tokenizer.pkl\", \"rb\"))\n",
        "\n",
        "# Compute Metrics\n",
        "bleu_scores = []\n",
        "rouge_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for i in range(len(actual_captions)):\n",
        "    bleu = calculate_bleu(actual_captions[i], predicted_captions[i])\n",
        "    rouge = calculate_rouge(actual_captions[i], predicted_captions[i])\n",
        "\n",
        "    actual_ids = words_to_ids(actual_captions[i], tokenizer)\n",
        "    predicted_ids = words_to_ids(predicted_captions[i], tokenizer)\n",
        "\n",
        "    # Ensure lengths match\n",
        "    min_len = min(len(actual_ids), len(predicted_ids))\n",
        "    actual_ids, predicted_ids = actual_ids[:min_len], predicted_ids[:min_len]\n",
        "\n",
        "    precision = precision_score(actual_ids, predicted_ids, average=\"macro\", zero_division=0)\n",
        "    recall = recall_score(actual_ids, predicted_ids, average=\"macro\", zero_division=0)\n",
        "    f1 = f1_score(actual_ids, predicted_ids, average=\"macro\", zero_division=0)\n",
        "\n",
        "    bleu_scores.append(bleu)\n",
        "    rouge_scores.append(rouge[\"rouge-l\"][\"f\"])\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Print Results\n",
        "print(f\"Average BLEU Score: {np.mean(bleu_scores):.4f}\")\n",
        "print(f\"Average ROUGE-L Score: {np.mean(rouge_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precision_scores):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recall_scores):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "so_7NZ11RuoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}